{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4003,"status":"ok","timestamp":1726678606215,"user":{"displayName":"Ghulam Mustafa Keero 17","userId":"10665355566643746421"},"user_tz":-300},"id":"GMGcoxrU2PXA","outputId":"d87b77cc-3512-4975-d2c1-92ae708c3740"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset URL: https://www.kaggle.com/datasets/loveall/appliances-energy-prediction\n","License(s): other\n","Downloading appliances-energy-prediction.zip to /content\n","  0% 0.00/1.71M [00:00<?, ?B/s]\n","100% 1.71M/1.71M [00:00<00:00, 136MB/s]\n"]}],"source":["!kaggle datasets download -d loveall/appliances-energy-prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1726678606216,"user":{"displayName":"Ghulam Mustafa Keero 17","userId":"10665355566643746421"},"user_tz":-300},"id":"-oUdRSp2-KHT","outputId":"44626477-e76e-4bb5-b35a-cf414579e722"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/appliances-energy-prediction.zip\n","  inflating: KAG_energydata_complete.csv  \n"]}],"source":["!unzip /content/appliances-energy-prediction.zip"]},{"cell_type":"markdown","metadata":{"id":"jAQ8Bzqh-UYV"},"source":["**Importing nesscessray libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ayZVJKt3_Qi"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error, r2_score\n","from sklearn.linear_model import LinearRegression\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from keras.callbacks import EarlyStopping\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","# Load the dataset\n","df1=pd.read_csv('/content/KAG_energydata_complete.csv')"]},{"cell_type":"markdown","metadata":{"id":"EFW6XtsE_Lut"},"source":["###Loding data Set"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":706,"status":"ok","timestamp":1726678618945,"user":{"displayName":"Ghulam Mustafa Keero 17","userId":"10665355566643746421"},"user_tz":-300},"id":"8pGY6QAATEzn","outputId":"4565490c-1747-4bb2-9ff7-c7a8c62a230c"},"outputs":[{"output_type":"stream","name":"stdout","text":["KNN on df1 Accuracy: 0.32\n","KNN on df1 Accuracy: 0.30\n","KNN on df1 Accuracy: 0.31\n","KNN on df1 Accuracy: 0.32\n"]}],"source":["\n","# Select relevant features and target variable (Assuming Appliances is the target variable)\n","X = df1[['T1', 'RH_1', 'T2', 'RH_2', 'T3', 'RH_3']]  # Example features\n","y = df1['Appliances']  # Target variable\n","\n","# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Normalize the data (KNN is sensitive to scale)\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Initialize KNN model with hyperparameters\n","knn1 = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto')\n","knn2 = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto')\n","knn3 = KNeighborsClassifier(n_neighbors=7, weights='distance', algorithm='auto')\n","knn4 = KNeighborsClassifier(n_neighbors=9, weights='distance', algorithm='auto')\n","\n","# Train the model\n","knn1.fit(X_train, y_train)\n","knn2.fit(X_train, y_train)\n","knn3.fit(X_train, y_train)\n","knn4.fit(X_train, y_train)\n","\n","# Predict the results\n","y_pred1 = knn1.predict(X_test)\n","y_pred2 = knn2.predict(X_test)\n","y_pred3 = knn3.predict(X_test)\n","y_pred4 = knn4.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy1 = accuracy_score(y_test, y_pred1)\n","print(f\"KNN on df1 Accuracy: {accuracy1:.2f}\")\n","\n","accuracy1 = accuracy_score(y_test, y_pred2)\n","print(f\"KNN on df1 Accuracy: {accuracy1:.2f}\")\n","\n","accuracy1 = accuracy_score(y_test, y_pred3)\n","print(f\"KNN on df1 Accuracy: {accuracy1:.2f}\")\n","\n","accuracy1 = accuracy_score(y_test, y_pred4)\n","print(f\"KNN on df1 Accuracy: {accuracy1:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"eNduIsM_pp8K"},"source":["### Now for svm"]},{"cell_type":"code","source":["df1.head()"],"metadata":{"id":"kuyRtfwKEm5J"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nXMiLqn0pvhZ"},"outputs":[],"source":["# Select relevant features and target variable (Assuming Appliances is the target variable)\n","X = df1[['T1', 'RH_1', 'T2', 'RH_2', 'T3', 'RH_3']]  # Example features\n","y = df1['Appliances']  # Target variable\n","\n","# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Normalize the data (KNN is sensitive to scale)\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Initialize 6 SVM models with different hyperparameters\n","svm1 = SVC(kernel='linear', C=1)\n","svm2 = SVC(kernel='rbf', C=1, gamma='scale')  # Radial Basis Function kernel\n","svm3 = SVC(kernel='poly', degree=3, C=3)      # Polynomial kernel\n","\n","# Train the model\n","svm1.fit(X_train, y_train)\n","svm2.fit(X_train, y_train)\n","svm3.fit(X_train, y_train)\n","svm4.fit(X_train, y_train)\n","\n","# Predict the results\n","y_pred1 = svm1.predict(X_test)\n","y_pred2 = svm2.predict(X_test)\n","y_pred3 = svm3.predict(X_test)\n","y_pred4 = svm4.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy1 = accuracy_score(y_test, y_pred1)\n","print(f\"svm on df1 Accuracy: {accuracy1:.2f}\")\n","\n","accuracy1 = accuracy_score(y_test, y_pred2)\n","print(f\"svm on df1 Accuracy: {accuracy1:.2f}\")\n","\n","accuracy1 = accuracy_score(y_test, y_pred3)\n","print(f\"svm on df1 Accuracy: {accuracy1:.2f}\")\n","\n","accuracy1 = accuracy_score(y_test, y_pred4)\n","print(f\"svm on df1 Accuracy: {accuracy1:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"eBMVj7iOx-s0"},"source":["### Now lets use ETC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r0cmYSCRyQg3"},"outputs":[],"source":["\n","from sklearn.ensemble import ExtraTreesClassifier\n","\n","# Select relevant features and target variable (Assuming Appliances is the target variable)\n","X = df1[['T1', 'RH_1', 'T2', 'RH_2', 'T3', 'RH_3']]  # Example features\n","y = df1['Appliances']  # Target variable\n","\n","# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize 4 ETC models with different hyperparameters\n","etc1 = ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=42)\n","etc2 = ExtraTreesClassifier(n_estimators=50, max_depth=10, min_samples_split=5, random_state=42)\n","etc3 = ExtraTreesClassifier(n_estimators=200, max_depth=15, min_samples_split=3, random_state=42)\n","etc4 = ExtraTreesClassifier(n_estimators=150, max_depth=20, min_samples_split=7, random_state=42)\n","\n","\n","# Train the models\n","etc1.fit(X_train, y_train)\n","etc2.fit(X_train, y_train)\n","etc3.fit(X_train, y_train)\n","etc4.fit(X_train, y_train)\n","\n","# Predict the results\n","y_pred1 = etc1.predict(X_test)\n","y_pred2 = etc2.predict(X_test)\n","y_pred3 = etc3.predict(X_test)\n","y_pred4 = etc4.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy1 = accuracy_score(y_test, y_pred1)\n","print(f\"ETC1 on df1 Accuracy: {accuracy1:.2f}\")\n","\n","accuracy2 = accuracy_score(y_test, y_pred2)\n","print(f\"ETC2 on df1 Accuracy: {accuracy2:.2f}\")\n","\n","accuracy3 = accuracy_score(y_test, y_pred3)\n","print(f\"ETC3 on df1 Accuracy: {accuracy3:.2f}\")\n","\n","accuracy4 = accuracy_score(y_test, y_pred4)\n","print(f\"ETC4 on df1 Accuracy: {accuracy4:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"L-u-bqLC26Jv"},"source":["Now lets do it for df1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"soe__Kc9yD15"},"outputs":[],"source":["# prompt: I have 4 RFC classifier generate code for it\n","\n","# Select relevant features and target variable (Assuming Appliances is the target variable)\n","X = df1[['T1', 'RH_1', 'T2', 'RH_2', 'T3', 'RH_3']]  # Example features\n","y = df1['Appliances']  # Target variable\n","\n","# Split the dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize 4 RFC models with different hyperparameters\n","rfc1 = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=42)\n","rfc2 = RandomForestClassifier(n_estimators=50, max_depth=10, min_samples_split=5, random_state=42)\n","\n","\n","# Train the models\n","rfc1.fit(X_train, y_train)\n","rfc2.fit(X_train, y_train)\n","\n","# Predict the results\n","y_pred1 = rfc1.predict(X_test)\n","y_pred2 = rfc2.predict(X_test)\n","\n","# Calculate accuracy\n","accuracy1 = accuracy_score(y_test, y_pred1)\n","print(f\"RFC1 on df1 Accuracy: {accuracy1:.2f}\")\n","\n","accuracy2 = accuracy_score(y_test, y_pred2)\n","print(f\"RFC2 on df1 Accuracy: {accuracy2:.2f}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mp6shUVpAtiU"},"outputs":[],"source":["\n","df2= pd.read_csv('/content/Panasonic_Employee_Reviews_from_AmbitionBox.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NkjFT-q_S6cT"},"outputs":[],"source":["# Import necessary libraries (if not already imported)\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","# Remove rows with missing values (NaN)\n","df2_cleaned = df2.dropna()\n","\n","# Prepare the cleaned dataset\n","X2 = df2_cleaned[['Title_encoded', 'Place_encoded', 'Job_type_encoded', 'work_life_balance', 'skill_development']]\n","y2 = df2_cleaned['Overall_rating']\n","\n","# Split the cleaned dataset\n","X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n","\n","# Normalize the data for df2\n","scaler2 = StandardScaler()\n","X2_train = scaler2.fit_transform(X2_train)\n","X2_test = scaler2.transform(X2_test)\n","\n","# Initialize KNN models with different hyperparameters\n","knn1 = KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='auto')\n","knn2 = KNeighborsClassifier(n_neighbors=7, weights='uniform', algorithm='auto')\n","knn3 = KNeighborsClassifier(n_neighbors=9, weights='distance', algorithm='auto')\n","\n","# Train the models on df2 data\n","knn1.fit(X2_train, y2_train)\n","knn2.fit(X2_train, y2_train)\n","knn3.fit(X2_train, y2_train)\n","\n","# Predict the results for df2\n","y_pred1 = knn1.predict(X2_test)\n","y_pred2 = knn2.predict(X2_test)\n","y_pred3 = knn3.predict(X2_test)\n","\n","# Calculate accuracy for each model\n","accuracy1 = accuracy_score(y2_test, y_pred1)\n","print(f\"KNN1 on df2 Accuracy: {accuracy1:.2f}\")\n","\n","accuracy2 = accuracy_score(y2_test, y_pred2)\n","print(f\"KNN2 on df2 Accuracy: {accuracy2:.2f}\")\n","\n","accuracy3 = accuracy_score(y2_test, y_pred3)\n","print(f\"KNN3 on df2 Accuracy: {accuracy3:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"n1irf45ao2Bs"},"source":["## Now lets do it for svm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0xWF5DiUo7h2"},"outputs":[],"source":["# Import necessary libraries (if not already imported)\n","from sklearn.svm import SVC  # Support Vector Classifier (SVM)\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.impute import SimpleImputer\n","\n","# Assuming df2 is already prepared with encoded and imputed values\n","# X2 = df2_cleaned[['Title_encoded', 'Place_encoded', 'Job_type_encoded', 'work_life_balance', 'skill_development']]\n","# y2 = df2_cleaned['Overall_rating']\n","\n","# Split the dataset\n","X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n","\n","# Normalize the data\n","scaler2 = StandardScaler()\n","X2_train = scaler2.fit_transform(X2_train)\n","X2_test = scaler2.transform(X2_test)\n","\n","# Initialize 6 SVM models with different hyperparameters\n","svm4 = SVC(kernel='linear', C=0.1)            # Linear kernel with lower regularization\n","svm5 = SVC(kernel='rbf', C=10, gamma='auto')  # Higher regularization\n","svm6 = SVC(kernel='sigmoid', C=1)             # Sigmoid kernel\n","\n","# Train each SVM model\n","svm4.fit(X2_train, y2_train)\n","svm5.fit(X2_train, y2_train)\n","svm6.fit(X2_train, y2_train)\n","\n","# Predict the results\n","y_pred4 = svm4.predict(X2_test)\n","y_pred5 = svm5.predict(X2_test)\n","y_pred6 = svm6.predict(X2_test)\n","\n","# Calculate accuracy for each SVM model\n","\n","accuracy4 = accuracy_score(y2_test, y_pred4)\n","print(f\"SVM4 Accuracy (Linear, C=0.1): {accuracy4:.2f}\")\n","\n","accuracy5 = accuracy_score(y2_test, y_pred5)\n","print(f\"SVM5 Accuracy (RBF, C=10, Gamma=auto): {accuracy5:.2f}\")\n","\n","accuracy6 = accuracy_score(y2_test, y_pred6)\n","print(f\"SVM6 Accuracy (Sigmoid, C=1): {accuracy6:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"PrNo6PFb09XG"},"source":["Now ETC FOR DF2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3KjaJGTZ1BRs"},"outputs":[],"source":["\n","# Assuming df2 is already prepared with encoded and imputed values\n","# X2 = df2_cleaned[['Title_encoded', 'Place_encoded', 'Job_type_encoded', 'work_life_balance', 'skill_development']]\n","# y2 = df2_cleaned['Overall_rating']\n","\n","# Split the dataset\n","X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n","\n","# Initialize 4 ETC models with different hyperparameters\n","etc7 = ExtraTreesClassifier(n_estimators=200, max_depth=15, min_samples_split=3, random_state=42)\n","etc8 = ExtraTreesClassifier(n_estimators=150, max_depth=20, min_samples_split=7, random_state=42)\n","\n","# Train the models\n","\n","etc7.fit(X2_train, y2_train)\n","etc8.fit(X2_train, y2_train)\n","\n","# Predict the results\n","y_pred7 = etc7.predict(X2_test)\n","y_pred8 = etc8.predict(X2_test)\n","\n","# Calculate accuracy\n","\n","accuracy7 = accuracy_score(y2_test, y_pred7)\n","print(f\"ETC7 on df2 Accuracy: {accuracy7:.2f}\")\n","\n","accuracy8 = accuracy_score(y2_test, y_pred8)\n","print(f\"ETC8 on df2 Accuracy: {accuracy8:.2f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"98uMWLvg2t2i"},"source":["Now lets do it for RFC"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"whOrDAN22zpW"},"outputs":[],"source":["# Now lets do it for RFC for df2\n","\n","# Assuming df2 is already prepared with encoded and imputed values\n","# X2 = df2_cleaned[['Title_encoded', 'Place_encoded', 'Job_type_encoded', 'work_life_balance', 'skill_development']]\n","# y2 = df2_cleaned['Overall_rating']\n","\n","# Split the dataset\n","X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n","\n","# Initialize 4 RFC models with different hyperparameters\n","rfc5 = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_split=3, random_state=42)\n","rfc6 = RandomForestClassifier(n_estimators=150, max_depth=20, min_samples_split=7, random_state=42)\n","\n","# Train the models\n","rfc5.fit(X2_train, y2_train)\n","rfc6.fit(X2_train, y2_train)\n","\n","# Predict the results\n","y_pred5 = rfc5.predict(X2_test)\n","y_pred6 = rfc6.predict(X2_test)\n","\n","# Calculate accuracy\n","\n","accuracy5 = accuracy_score(y2_test, y_pred5)\n","print(f\"RFC5 on df2 Accuracy: {accuracy5:.2f}\")\n","\n","accuracy6 = accuracy_score(y2_test, y_pred6)\n","print(f\"RFC6 on df2 Accuracy: {accuracy6:.2f}\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"Lz0q8pMCduyw","executionInfo":{"status":"ok","timestamp":1734606226611,"user_tz":-300,"elapsed":751,"user":{"displayName":"Ghulam Mustafa Keero 17","userId":"10665355566643746421"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyNbZZwd3M6Baid4birtZuBd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}